{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch 模型转换为 ONNX 格式"
      ],
      "metadata": {
        "id": "2iy7XoQqg29R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 安装 ONNX 库"
      ],
      "metadata": {
        "id": "DoO8VRiNYNbT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCh5Vl3XXhwE",
        "outputId": "c047e8fb-7e26-41d3-e75a-891bab6ca637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.16.1\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 导出 PyTorch 模型到 ONNX"
      ],
      "metadata": {
        "id": "jNMxKu_0YwoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torch.utils.model_zoo as modelzoo\n",
        "import torch.onnx"
      ],
      "metadata": {
        "id": "GT3FX5IdcKlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18_url = 'https://download.pytorch.org/models/resnet18-5c106cde.pth'\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_chan, out_chan, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_chan, out_chan, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(out_chan)\n",
        "        self.conv2 = conv3x3(out_chan, out_chan)\n",
        "        self.bn2 = nn.BatchNorm2d(out_chan)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = None\n",
        "        if in_chan != out_chan or stride != 1:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_chan, out_chan,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_chan),\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.conv1(x)\n",
        "        residual = F.relu(self.bn1(residual))\n",
        "        residual = self.conv2(residual)\n",
        "        residual = self.bn2(residual)\n",
        "\n",
        "        shortcut = x\n",
        "        if self.downsample is not None:\n",
        "            shortcut = self.downsample(x)\n",
        "\n",
        "        out = shortcut + residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def create_layer_basic(in_chan, out_chan, bnum, stride=1):\n",
        "    layers = [BasicBlock(in_chan, out_chan, stride=stride)]\n",
        "    for i in range(bnum-1):\n",
        "        layers.append(BasicBlock(out_chan, out_chan, stride=1))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class Resnet18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Resnet18, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = create_layer_basic(64, 64, bnum=2, stride=1)\n",
        "        self.layer2 = create_layer_basic(64, 128, bnum=2, stride=2)\n",
        "        self.layer3 = create_layer_basic(128, 256, bnum=2, stride=2)\n",
        "        self.layer4 = create_layer_basic(256, 512, bnum=2, stride=2)\n",
        "        self.init_weight()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(self.bn1(x))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        feat8 = self.layer2(x) # 1/8\n",
        "        feat16 = self.layer3(feat8) # 1/16\n",
        "        feat32 = self.layer4(feat16) # 1/32\n",
        "        return feat8, feat16, feat32\n",
        "\n",
        "    def init_weight(self):\n",
        "        state_dict = modelzoo.load_url(resnet18_url)\n",
        "        self_state_dict = self.state_dict()\n",
        "        for k, v in state_dict.items():\n",
        "            if 'fc' in k: continue\n",
        "            self_state_dict.update({k: v})\n",
        "        self.load_state_dict(self_state_dict)\n",
        "\n",
        "    def get_params(self):\n",
        "        wd_params, nowd_params = [], []\n",
        "        for name, module in self.named_modules():\n",
        "            if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
        "                wd_params.append(module.weight)\n",
        "                if not module.bias is None:\n",
        "                    nowd_params.append(module.bias)\n",
        "            elif isinstance(module,  nn.BatchNorm2d):\n",
        "                nowd_params += list(module.parameters())\n",
        "        return wd_params, nowd_params"
      ],
      "metadata": {
        "id": "-GD-yvoTcC0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBNReLU(nn.Module):\n",
        "    def __init__(self, in_chan, out_chan, ks=3, stride=1, padding=1, *args, **kwargs):\n",
        "        super(ConvBNReLU, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_chan,\n",
        "                out_chan,\n",
        "                kernel_size = ks,\n",
        "                stride = stride,\n",
        "                padding = padding,\n",
        "                bias = False)\n",
        "        self.bn = nn.BatchNorm2d(out_chan)\n",
        "        self.init_weight()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = F.relu(self.bn(x))\n",
        "        return x\n",
        "\n",
        "    def init_weight(self):\n",
        "        for ly in self.children():\n",
        "            if isinstance(ly, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(ly.weight, a=1)\n",
        "                if not ly.bias is None: nn.init.constant_(ly.bias, 0)\n",
        "\n",
        "class BiSeNetOutput(nn.Module):\n",
        "    def __init__(self, in_chan, mid_chan, n_classes, *args, **kwargs):\n",
        "        super(BiSeNetOutput, self).__init__()\n",
        "        self.conv = ConvBNReLU(in_chan, mid_chan, ks=3, stride=1, padding=1)\n",
        "        self.conv_out = nn.Conv2d(mid_chan, n_classes, kernel_size=1, bias=False)\n",
        "        self.init_weight()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.conv_out(x)\n",
        "        return x\n",
        "\n",
        "    def init_weight(self):\n",
        "        for ly in self.children():\n",
        "            if isinstance(ly, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(ly.weight, a=1)\n",
        "                if not ly.bias is None: nn.init.constant_(ly.bias, 0)\n",
        "\n",
        "    def get_params(self):\n",
        "        wd_params, nowd_params = [], []\n",
        "        for name, module in self.named_modules():\n",
        "            if isinstance(module, nn.Linear) or isinstance(module, nn.Conv2d):\n",
        "                wd_params.append(module.weight)\n",
        "                if not module.bias is None:\n",
        "                    nowd_params.append(module.bias)\n",
        "            elif isinstance(module, nn.BatchNorm2d):\n",
        "                nowd_params += list(module.parameters())\n",
        "        return wd_params, nowd_params\n",
        "\n",
        "\n",
        "class AttentionRefinementModule(nn.Module):\n",
        "    def __init__(self, in_chan, out_chan, *args, **kwargs):\n",
        "        super(AttentionRefinementModule, self).__init__()\n",
        "        self.conv = ConvBNReLU(in_chan, out_chan, ks=3, stride=1, padding=1)\n",
        "        self.conv_atten = nn.Conv2d(out_chan, out_chan, kernel_size= 1, bias=False)\n",
        "        self.bn_atten = nn.BatchNorm2d(out_chan)\n",
        "        self.sigmoid_atten = nn.Sigmoid()\n",
        "        self.init_weight()\n",
        "\n",
        "    def forward(self, x):\n",
        "        feat = self.conv(x)\n",
        "        atten = F.avg_pool2d(feat, feat.size()[2:])\n",
        "        atten = self.conv_atten(atten)\n",
        "        atten = self.bn_atten(atten)\n",
        "        atten = self.sigmoid_atten(atten)\n",
        "        out = torch.mul(feat, atten)\n",
        "        return out\n",
        "\n",
        "    def init_weight(self):\n",
        "        for ly in self.children():\n",
        "            if isinstance(ly, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(ly.weight, a=1)\n",
        "                if not ly.bias is None: nn.init.constant_(ly.bias, 0)\n",
        "\n",
        "\n",
        "class ContextPath(nn.Module):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(ContextPath, self).__init__()\n",
        "        self.resnet = Resnet18()\n",
        "        self.arm16 = AttentionRefinementModule(256, 128)\n",
        "        self.arm32 = AttentionRefinementModule(512, 128)\n",
        "        self.conv_head32 = ConvBNReLU(128, 128, ks=3, stride=1, padding=1)\n",
        "        self.conv_head16 = ConvBNReLU(128, 128, ks=3, stride=1, padding=1)\n",
        "        self.conv_avg = ConvBNReLU(512, 128, ks=1, stride=1, padding=0)\n",
        "\n",
        "        self.init_weight()\n",
        "\n",
        "    def forward(self, x):\n",
        "        H0, W0 = x.size()[2:]\n",
        "        feat8, feat16, feat32 = self.resnet(x)\n",
        "        H8, W8 = feat8.size()[2:]\n",
        "        H16, W16 = feat16.size()[2:]\n",
        "        H32, W32 = feat32.size()[2:]\n",
        "\n",
        "        avg = F.avg_pool2d(feat32, feat32.size()[2:])\n",
        "        avg = self.conv_avg(avg)\n",
        "        avg_up = F.interpolate(avg, (H32, W32), mode='nearest')\n",
        "\n",
        "        feat32_arm = self.arm32(feat32)\n",
        "        feat32_sum = feat32_arm + avg_up\n",
        "        feat32_up = F.interpolate(feat32_sum, (H16, W16), mode='nearest')\n",
        "        feat32_up = self.conv_head32(feat32_up)\n",
        "\n",
        "        feat16_arm = self.arm16(feat16)\n",
        "        feat16_sum = feat16_arm + feat32_up\n",
        "        feat16_up = F.interpolate(feat16_sum, (H8, W8), mode='nearest')\n",
        "        feat16_up = self.conv_head16(feat16_up)\n",
        "\n",
        "        return feat8, feat16_up, feat32_up  # x8, x8, x16\n",
        "\n",
        "    def init_weight(self):\n",
        "        for ly in self.children():\n",
        "            if isinstance(ly, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(ly.weight, a=1)\n",
        "                if not ly.bias is None: nn.init.constant_(ly.bias, 0)\n",
        "\n",
        "    def get_params(self):\n",
        "        wd_params, nowd_params = [], []\n",
        "        for name, module in self.named_modules():\n",
        "            if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
        "                wd_params.append(module.weight)\n",
        "                if not module.bias is None:\n",
        "                    nowd_params.append(module.bias)\n",
        "            elif isinstance(module, nn.BatchNorm2d):\n",
        "                nowd_params += list(module.parameters())\n",
        "        return wd_params, nowd_params\n",
        "\n",
        "\n",
        "### This is not used, since I replace this with the resnet feature with the same size\n",
        "class SpatialPath(nn.Module):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(SpatialPath, self).__init__()\n",
        "        self.conv1 = ConvBNReLU(3, 64, ks=7, stride=2, padding=3)\n",
        "        self.conv2 = ConvBNReLU(64, 64, ks=3, stride=2, padding=1)\n",
        "        self.conv3 = ConvBNReLU(64, 64, ks=3, stride=2, padding=1)\n",
        "        self.conv_out = ConvBNReLU(64, 128, ks=1, stride=1, padding=0)\n",
        "        self.init_weight()\n",
        "\n",
        "    def forward(self, x):\n",
        "        feat = self.conv1(x)\n",
        "        feat = self.conv2(feat)\n",
        "        feat = self.conv3(feat)\n",
        "        feat = self.conv_out(feat)\n",
        "        return feat\n",
        "\n",
        "    def init_weight(self):\n",
        "        for ly in self.children():\n",
        "            if isinstance(ly, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(ly.weight, a=1)\n",
        "                if not ly.bias is None: nn.init.constant_(ly.bias, 0)\n",
        "\n",
        "    def get_params(self):\n",
        "        wd_params, nowd_params = [], []\n",
        "        for name, module in self.named_modules():\n",
        "            if isinstance(module, nn.Linear) or isinstance(module, nn.Conv2d):\n",
        "                wd_params.append(module.weight)\n",
        "                if not module.bias is None:\n",
        "                    nowd_params.append(module.bias)\n",
        "            elif isinstance(module, nn.BatchNorm2d):\n",
        "                nowd_params += list(module.parameters())\n",
        "        return wd_params, nowd_params\n",
        "\n",
        "\n",
        "class FeatureFusionModule(nn.Module):\n",
        "    def __init__(self, in_chan, out_chan, *args, **kwargs):\n",
        "        super(FeatureFusionModule, self).__init__()\n",
        "        self.convblk = ConvBNReLU(in_chan, out_chan, ks=1, stride=1, padding=0)\n",
        "        self.conv1 = nn.Conv2d(out_chan,\n",
        "                out_chan//4,\n",
        "                kernel_size = 1,\n",
        "                stride = 1,\n",
        "                padding = 0,\n",
        "                bias = False)\n",
        "        self.conv2 = nn.Conv2d(out_chan//4,\n",
        "                out_chan,\n",
        "                kernel_size = 1,\n",
        "                stride = 1,\n",
        "                padding = 0,\n",
        "                bias = False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.init_weight()\n",
        "\n",
        "    def forward(self, fsp, fcp):\n",
        "        fcat = torch.cat([fsp, fcp], dim=1)\n",
        "        feat = self.convblk(fcat)\n",
        "        atten = F.avg_pool2d(feat, feat.size()[2:])\n",
        "        atten = self.conv1(atten)\n",
        "        atten = self.relu(atten)\n",
        "        atten = self.conv2(atten)\n",
        "        atten = self.sigmoid(atten)\n",
        "        feat_atten = torch.mul(feat, atten)\n",
        "        feat_out = feat_atten + feat\n",
        "        return feat_out\n",
        "\n",
        "    def init_weight(self):\n",
        "        for ly in self.children():\n",
        "            if isinstance(ly, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(ly.weight, a=1)\n",
        "                if not ly.bias is None: nn.init.constant_(ly.bias, 0)\n",
        "\n",
        "    def get_params(self):\n",
        "        wd_params, nowd_params = [], []\n",
        "        for name, module in self.named_modules():\n",
        "            if isinstance(module, nn.Linear) or isinstance(module, nn.Conv2d):\n",
        "                wd_params.append(module.weight)\n",
        "                if not module.bias is None:\n",
        "                    nowd_params.append(module.bias)\n",
        "            elif isinstance(module, nn.BatchNorm2d):\n",
        "                nowd_params += list(module.parameters())\n",
        "        return wd_params, nowd_params\n",
        "\n",
        "\n",
        "class BiSeNet(nn.Module):\n",
        "    def __init__(self, n_classes, *args, **kwargs):\n",
        "        super(BiSeNet, self).__init__()\n",
        "        self.cp = ContextPath()\n",
        "        ## here self.sp is deleted\n",
        "        self.ffm = FeatureFusionModule(256, 256)\n",
        "        self.conv_out = BiSeNetOutput(256, 256, n_classes)\n",
        "        self.conv_out16 = BiSeNetOutput(128, 64, n_classes)\n",
        "        self.conv_out32 = BiSeNetOutput(128, 64, n_classes)\n",
        "        self.init_weight()\n",
        "\n",
        "    def forward(self, x):\n",
        "        H, W = x.size()[2:]\n",
        "        feat_res8, feat_cp8, feat_cp16 = self.cp(x)  # here return res3b1 feature\n",
        "        feat_sp = feat_res8  # use res3b1 feature to replace spatial path feature\n",
        "        feat_fuse = self.ffm(feat_sp, feat_cp8)\n",
        "\n",
        "        feat_out = self.conv_out(feat_fuse)\n",
        "        feat_out16 = self.conv_out16(feat_cp8)\n",
        "        feat_out32 = self.conv_out32(feat_cp16)\n",
        "\n",
        "        feat_out = F.interpolate(feat_out, (H, W), mode='bilinear', align_corners=True)\n",
        "        feat_out16 = F.interpolate(feat_out16, (H, W), mode='bilinear', align_corners=True)\n",
        "        feat_out32 = F.interpolate(feat_out32, (H, W), mode='bilinear', align_corners=True)\n",
        "        return feat_out, feat_out16, feat_out32\n",
        "\n",
        "    def init_weight(self):\n",
        "        for ly in self.children():\n",
        "            if isinstance(ly, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(ly.weight, a=1)\n",
        "                if not ly.bias is None: nn.init.constant_(ly.bias, 0)\n",
        "\n",
        "    def get_params(self):\n",
        "        wd_params, nowd_params, lr_mul_wd_params, lr_mul_nowd_params = [], [], [], []\n",
        "        for name, child in self.named_children():\n",
        "            child_wd_params, child_nowd_params = child.get_params()\n",
        "            if isinstance(child, FeatureFusionModule) or isinstance(child, BiSeNetOutput):\n",
        "                lr_mul_wd_params += child_wd_params\n",
        "                lr_mul_nowd_params += child_nowd_params\n",
        "            else:\n",
        "                wd_params += child_wd_params\n",
        "                nowd_params += child_nowd_params\n",
        "        return wd_params, nowd_params, lr_mul_wd_params, lr_mul_nowd_params"
      ],
      "metadata": {
        "id": "cb1kAUS4Y0tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 19\n",
        "model = BiSeNet(n_classes)\n",
        "model_path = '/content/drive/MyDrive/Colab Notebooks/79999_iter.pth'\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()\n",
        "dummy_input = torch.randn(1, 3, 512, 512)\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    dummy_input,\n",
        "    '/content/drive/MyDrive/Colab Notebooks/79999_iter.onnx',\n",
        "    export_params=True,\n",
        "    opset_version=11,\n",
        "    do_constant_folding=True,\n",
        "    input_names=['input'],\n",
        "    output_names=['output']\n",
        ")"
      ],
      "metadata": {
        "id": "LGT1DpjScbCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 检查导出的 ONNX 模型是否有效"
      ],
      "metadata": {
        "id": "y1sSd6HNfrmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "onnx_model_path = '/content/drive/MyDrive/Colab Notebooks/79999_iter.onnx'\n",
        "onnx_model = onnx.load(onnx_model_path)\n",
        "onnx.checker.check_model(onnx_model)\n",
        "\n",
        "print('ONNX model is valid!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8OqzNjdft_s",
        "outputId": "49f41c12-6b30-45d1-bcbd-39a81e05d54f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX model is valid!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONNX 模型转换为 TensorFlow Lite 格式"
      ],
      "metadata": {
        "id": "R5x5lV6Dg7va"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 将 ONNX 转换为 TensorFlow 格式"
      ],
      "metadata": {
        "id": "Oj2atwnxhJb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx-tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Quev8k7ehMzV",
        "outputId": "be5b15d4-288d-4ae1-a175-1120183662cd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx-tf\n",
            "  Downloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: onnx>=1.10.2 in /usr/local/lib/python3.10/dist-packages (from onnx-tf) (1.16.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from onnx-tf) (6.0.1)\n",
            "Collecting tensorflow-addons (from onnx-tf)\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx-tf) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx-tf) (3.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons->onnx-tf) (24.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->onnx-tf)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons, onnx-tf\n",
            "Successfully installed onnx-tf-1.10.0 tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from onnx_tf.backend import prepare\n",
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load('/content/drive/MyDrive/Colab Notebooks/79999_iter.onnx')\n",
        "tf_rep = prepare(onnx_model)\n",
        "tf_rep.export_graph('/content/drive/MyDrive/Colab Notebooks/79999_iter.pb')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF6kPqk7hfax",
        "outputId": "c311c276-8c65-4047-9f0d-4ffaadb2bf4b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: resize_nearest_neighbor (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.image.resize(...method=ResizeMethod.NEAREST_NEIGHBOR...)` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: resize_bilinear (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.image.resize(...method=ResizeMethod.BILINEAR...)` instead.\n",
            "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_121_x, add_37_y in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "INFO:absl:Writing fingerprint to /content/drive/MyDrive/Colab Notebooks/79999_iter.pb/fingerprint.pb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 将 TensorFlow 模型转换为 TensorFlow Lite 格式"
      ],
      "metadata": {
        "id": "MfX8eI18h-EX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('/content/drive/MyDrive/Colab Notebooks/79999_iter.pb')\n",
        "tflite_model = converter.convert()\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/79999_iter.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "bTzjuqKsmK8v"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}